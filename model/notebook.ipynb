{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "dOQeAqJAeSNv",
        "colab_type": "code",
        "outputId": "8c4a74d5-e325-4dee-aa30-99613fbcbdd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from joblib import dump, load\n",
        "from typing import List, Any, Dict\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import SGDClassifier #, LogisticRegression\n",
        "#from sklearn.preprocessing import Binarizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "id": "FJ6o9UoWeoK_",
        "colab_type": "code",
        "outputId": "f0603e31-507a-415d-fb6d-66ae9e2a15fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./dataset_for_assignment.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        comment_text  target\n",
              "0  Explanation\\nWhy the edits made under my usern...       0\n",
              "1  D'aww! He matches this background colour I'm s...       0\n",
              "2  Hey man, I'm really not trying to edit war. It...       0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...       0\n",
              "4  You, sir, are my hero. Any chance you remember...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "e6upJ7zKgdrv",
        "colab_type": "code",
        "outputId": "c82c7d6a-0b44-4eeb-c78c-c00748faa1d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "groups = df.groupby(['target']).agg({'target': 'count'}).to_dict('index')\n",
        "print(groups[1]['target'], groups[0]['target'])\n",
        "groups[1]['target'] / groups[0]['target']"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16225 143346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1131876717871444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "BITu1tdI2ZLm",
        "colab_type": "code",
        "outputId": "bd330799-e73d-4812-9380-5c17a9555001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;\\\\n]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def loss_0_1(model, xs: List[str], ys: List[int]):\n",
        "  # validation on class \"0\" samples that were not incuded in train process\n",
        "  predicted = model.predict(xs)\n",
        "  return np.mean(predicted == ys)\n",
        "  #print(\"class 0 recall:\", np.mean(predicted == ys))\n",
        "  #print(metrics.classification_report(y_true=df_other_class_0.target.tolist(), y_pred=predicted))\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    '''Clean text'''\n",
        "       \n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text\n",
        "    \n",
        "df['comment_text'] = df['comment_text'].apply(clean_text)\n",
        "df.head()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>explanation edits made username hardcore metal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>daww matches background colour im seemingly st...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hey man im really trying edit war guy constant...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cant make real suggestions improvement wondere...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sir hero chance remember page thats</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        comment_text  target\n",
              "0  explanation edits made username hardcore metal...       0\n",
              "1  daww matches background colour im seemingly st...       0\n",
              "2  hey man im really trying edit war guy constant...       0\n",
              "3  cant make real suggestions improvement wondere...       0\n",
              "4                sir hero chance remember page thats       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "zLR30j_1ieBf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset Undersampling\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xcdMk7Pf4q7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indexies_class_0 = df[df.target == 0].index.tolist()\n",
        "indexies_class_1 = df[df.target == 1].index.tolist()\n",
        "random_indices_class_0 = np.random.choice(indexies_class_0, len(indexies_class_1), replace=False).tolist()\n",
        "\n",
        "df_balanced = df.loc[random_indices_class_0 + indexies_class_1]\n",
        "df_other_class_0 = df.loc[~df.index.isin(random_indices_class_0 + indexies_class_1)]\n",
        "#df_balanced.groupby(['target']).agg({'target': 'count'})\n",
        "\n",
        "df_train, df_test = train_test_split(df, shuffle=True, test_size=0.15)\n",
        "df_train_b, df_test_b = train_test_split(df_balanced, shuffle=True, test_size=0.15)\n",
        "\n",
        "X = df_train.comment_text.tolist()\n",
        "Y = df_train.target.tolist()\n",
        "Xb = df_train_b.comment_text.tolist()\n",
        "Yb = df_train_b.target.tolist()\n",
        "\n",
        "\n",
        "# def undersample(df: pd.DataFrame, y, enabled):\n",
        "#   indexies_class_0 = df[df.target == 0].index.tolist()\n",
        "#   indexies_class_1 = df[df.target == 1].index.tolist()\n",
        "#   random_indices_class_0 = np.random.choice(indexies_class_0, len(indexies_class_1), replace=False).tolist()\n",
        "#   df_balanced = df.loc[random_indices_class_0 + indexies_class_1]\n",
        "#   print('=====df=df=====')\n",
        "#   return df_balanced.comment_text.tolist()\n",
        "\n",
        "# def undersample2(X):\n",
        "#   print(\"===undersample2===\")\n",
        "# #   indexies_class_0 = df[df.target == 0].index.tolist()\n",
        "# #   indexies_class_1 = df[df.target == 1].index.tolist()\n",
        "# #   random_indices_class_0 = np.random.choice(indexies_class_0, len(indexies_class_1), replace=False).tolist()\n",
        "# #   df_balanced = df.loc[random_indices_class_0 + indexies_class_1]\n",
        "#   return X\n",
        "  \n",
        "def mk_clf_report(\n",
        "    pipeline, \n",
        "    parameters, \n",
        "    df_train, \n",
        "    df_test, \n",
        "    df_other_class_0=None\n",
        "  ):\n",
        "  \n",
        "  X = df_train.comment_text.tolist()\n",
        "  Y = df_train.target.tolist()\n",
        "  \n",
        "  gs = GridSearchCV(pipeline, parameters, cv=5, iid=False, n_jobs=-1)\n",
        "  gs = gs.fit(X, Y)\n",
        "  \n",
        "  # test\n",
        "  predicted = gs.predict(df_test.comment_text.tolist())\n",
        "  report = classification_report(\n",
        "      y_true=df_test.target.tolist(), \n",
        "      y_pred=predicted\n",
        "  )\n",
        "  if df_other_class_0 is not None:\n",
        "    loss = loss_0_1(\n",
        "        gs,\n",
        "        df_other_class_0.comment_text.tolist(), \n",
        "        df_other_class_0.target.tolist()\n",
        "    )\n",
        "  else:\n",
        "    loss = None\n",
        "    \n",
        "  return gs, report, loss\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CbAdUt8ildJ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "M6fzO3V55I59",
        "colab_type": "code",
        "outputId": "ae0f3bbd-88d7-4f62-ac9d-58ed877bafe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "ppl = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "    ('clf', MultinomialNB(fit_prior=False)),\n",
        "])\n",
        "\n",
        "parameters = {\n",
        "  'tfidf__use_idf': [True, False],\n",
        "  'clf__fit_prior': [True, False]\n",
        "}\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96     21409\n",
            "           1       0.84      0.45      0.59      2527\n",
            "\n",
            "   micro avg       0.93      0.93      0.93     23936\n",
            "   macro avg       0.89      0.72      0.78     23936\n",
            "weighted avg       0.93      0.93      0.92     23936\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rkpe8IuFPlgP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Imbalanced dataset"
      ]
    },
    {
      "metadata": {
        "id": "F2Wwl6J1P_GU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gs, report, loss = mk_clf_report(ppl, parameters, df_train, df_test)\n",
        "print(report)\n",
        "print(f'Best params:', {gs.best_params_})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "smypIxxVPvso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Balanced dataset"
      ]
    },
    {
      "metadata": {
        "id": "6LwknIUoQAOO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6350f7eb-b10e-4825-b213-a22d9324a607"
      },
      "cell_type": "code",
      "source": [
        "gs, report, loss = mk_clf_report(ppl, parameters, df_train_b, df_test_b, df_other_class_0)\n",
        "print(report)\n",
        "print('Best params:', gs.best_params_)\n",
        "print('0-1 loss for sample of only class \"0\":', loss)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89      2489\n",
            "           1       0.89      0.87      0.88      2379\n",
            "\n",
            "   micro avg       0.88      0.88      0.88      4868\n",
            "   macro avg       0.88      0.88      0.88      4868\n",
            "weighted avg       0.88      0.88      0.88      4868\n",
            "\n",
            "Best params: {'tfidf__use_idf': True}\n",
            "0-1 loss for samples of class \"0\": 0.8949032811258565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x4E6Crz_2efs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bernuolli Naive Bayes\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "z4VOBLftmKsL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ppl = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "    ('clf', BernoulliNB(binarize=0.0, fit_prior=True)),\n",
        "])\n",
        "\n",
        "parameters = {\n",
        "  'tfidf__use_idf': [True, False],\n",
        "  'clf__fit_prior': [True, False]\n",
        "}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T23kr0eYRvdu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Imbalanced dataset"
      ]
    },
    {
      "metadata": {
        "id": "cl_RGbV9Rw11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "3650a160-bf75-4828-ac07-ff7225063644"
      },
      "cell_type": "code",
      "source": [
        "gs, report, loss = mk_clf_report(ppl, parameters, df_train, df_test)\n",
        "print(report)\n",
        "print('Best params:', gs.best_params_)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     21399\n",
            "           1       0.89      0.55      0.68      2537\n",
            "\n",
            "   micro avg       0.94      0.94      0.94     23936\n",
            "   macro avg       0.92      0.77      0.82     23936\n",
            "weighted avg       0.94      0.94      0.94     23936\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-807c7a6774b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmk_clf_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best params:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bHV8KxoMRw_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Balanced dataset"
      ]
    },
    {
      "metadata": {
        "id": "_9Y8X2ZgRyVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "00ae3630-8d40-4ee5-9673-83e0abf848e9"
      },
      "cell_type": "code",
      "source": [
        "gs, report, loss = mk_clf_report(ppl, parameters, df_train_b, df_test_b, df_other_class_0)\n",
        "print(report)\n",
        "print('Best params:', gs.best_params_)\n",
        "print('0-1 loss for sample of only class \"0\":', loss)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.52      0.65      2489\n",
            "           1       0.65      0.92      0.76      2379\n",
            "\n",
            "   micro avg       0.72      0.72      0.72      4868\n",
            "   macro avg       0.76      0.72      0.71      4868\n",
            "weighted avg       0.76      0.72      0.71      4868\n",
            "\n",
            "Best params: {'tfidf__use_idf': True}\n",
            "0-1 loss for sample of only class \"0\": 0.5209052792221585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-9q7IznKqUm-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SVM & Logistic Regression\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "F5eeKGF1Ano6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ppl = Pipeline([\n",
        "    ('l0', CountVectorizer()),\n",
        "    ('l1', TfidfTransformer(use_idf=True)),\n",
        "    ('l3', SGDClassifier(\n",
        "        loss='hinge', \n",
        "        penalty='l2', \n",
        "        alpha=1e-5, \n",
        "        random_state=17, \n",
        "        max_iter=10, \n",
        "        tol=None,\n",
        "        early_stopping=True,\n",
        "        #validation_fraction=0.2\n",
        "    )),\n",
        "])\n",
        "parameters = {\n",
        "  'l1__use_idf': [True],\n",
        "  'l3__alpha': [1e-5, 1e-4],\n",
        "  'l3__loss': ['hinge', 'log'],\n",
        "  'l3__penalty': ['l2', 'l1']\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zPoAPZJVSNei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Imbalanced dataset"
      ]
    },
    {
      "metadata": {
        "id": "OE_SlhoDSONy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "ab16f50a-81ad-4ff2-aa7b-ea8602861ce5"
      },
      "cell_type": "code",
      "source": [
        "gs, report, loss = mk_clf_report(ppl, parameters, df_train, df_test)\n",
        "print(report)\n",
        "print('Best params:', gs.best_params_)\n",
        "dump(gs.best_estimator_, 'SGDClassifier.joblib')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98     21473\n",
            "           1       0.91      0.66      0.77      2463\n",
            "\n",
            "   micro avg       0.96      0.96      0.96     23936\n",
            "   macro avg       0.94      0.83      0.87     23936\n",
            "weighted avg       0.96      0.96      0.96     23936\n",
            "\n",
            "Best params: {'l1__use_idf': True, 'l3__alpha': 1e-05, 'l3__loss': 'hinge', 'l3__penalty': 'l2'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SGDClassifier.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "metadata": {
        "id": "fi_qOcRQSOY0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Balanced dataset"
      ]
    },
    {
      "metadata": {
        "id": "O09Of5BD2tsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "b6b4f2f3-f52e-474b-efb0-3444482dd7f9"
      },
      "cell_type": "code",
      "source": [
        "gs, report, loss = mk_clf_report(ppl, parameters, df_train_b, df_test_b, df_other_class_0)\n",
        "print(report)\n",
        "print('Best params:', gs.best_params_)\n",
        "print('0-1 loss for sample of only class \"0\":', loss)\n",
        "\n",
        "dump(gs.best_estimator_, 'SGDClassifier_balanced.joblib')\n"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91      2436\n",
            "           1       0.93      0.88      0.90      2432\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      4868\n",
            "   macro avg       0.91      0.90      0.90      4868\n",
            "weighted avg       0.91      0.90      0.90      4868\n",
            "\n",
            "Best params: {'l1__use_idf': True, 'l3__alpha': 1e-05, 'l3__loss': 'log', 'l3__penalty': 'l1'}\n",
            "0-1 loss for sample of only class \"0\": 0.9271638832293642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SGDClassifier_balanced.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "metadata": {
        "id": "EYDjNsqdWNtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "494877ef-dee3-4dc9-e423-d3f01736fc92"
      },
      "cell_type": "code",
      "source": [
        "model = load('SGDClassifier.joblib')\n",
        "model.predict(['hello from planet earth'])\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 160734)\t0.4679595972134574\n",
            "  (0, 98927)\t0.297785570592945\n",
            "  (0, 87851)\t0.7215564558847756\n",
            "  (0, 72885)\t0.4143595664316861\n",
            "\n",
            "   (0, 160734)\t0.4679595972134574\n",
            "  (0, 98927)\t0.297785570592945\n",
            "  (0, 87851)\t0.7215564558847756\n",
            "  (0, 72885)\t0.4143595664316861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "metadata": {
        "id": "XUrSFE86bLei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f1be0e7-0e90-4850-ed88-83ffdd721b13"
      },
      "cell_type": "code",
      "source": [
        "model = load('SGDClassifier.joblib')\n",
        "model.predict(['love me'])"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    }
  ]
}